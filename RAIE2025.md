---
layout: page
title: RAIE 2025
---

<!-- <p><img src="/img/pierrebourque.jpg" width="200" /><a href="https://profs.etsmtl.ca/pbourque">Pierre Bourque</a> - ing., Ph.D.</p> -->

# 3rd International Workshop on Responsible AI Engineering (RAIE'25)

***Co-located with [47th International Conference on Software Engineering (ICSE 2025)](https://conf.researchr.org/home/icse-2025), Ottawa, Ontario, Canada, April 27-May 3, 2025***

### Theme & Goals

The rapid advancements in AI, particularly the release of large language models (LLMs) and their applications, have attracted significant global interest and raised substantial concerns on responsible AI and AI safety. While LLMs are impressive examples of AI models, it is the compound AI systems, which integrate these models with other key components for function and quality/risk control, that are ultimately deployed and have real-world impact. These AI systems, especially autonomous LLM agents and those involving multi--agent interacting, require careful system-level engineering to ensure responsible AI and AI safety. 

In recent years, numerous regulations, principles, and guidelines for responsible AI and AI safety have been issued by governments, research organizations, and enterprises. However, they are typically very high-level and do not provide concrete guidance for technologists on how to implement responsible and safe AI. Developing responsible AI systems goes beyond fixing traditional software code "bugs" and providing theoretical guarantees for algorithms. New and improved software/AI engineering approaches are required to ensure that AI systems are trustworthy and safe throughout their entire lifecycle and trusted by those who use and rely on them.

Achieving responsible AI engineering—building adequate software engineering tools to support the responsible development of AI systems—requires a comprehensive understanding of human expectations and the utilization context of AI systems. This workshop aims to bring together researchers and practitioners not only in software engineering and AI but also ethicists, and experts from social sciences and regulatory bodies to build a community that will tackle the responsible/safe AI engineering challenges practitioners face in developing responsible and safe AI systems. Traditional software engineering methods are not sufficient to tackle the unique challenges posed by advanced AI technologies. This workshop will provide valuable insights into how software engineering can evolve to meet these challenges, focusing on aspects such as requirement engineering, architecture and design, verification and validation, and operational processes like DevOps and AgentOps. By bringing together experts from various fields, the workshop aims to foster interdisciplinary collaboration that will drive the advancement of responsible AI and AI safety engineering practices.

The primary objectives of this workshop are to:

1. Share cutting-edge software/AI engineering methods, techniques, tools, and real-world case studies that can help ensure responsible AI and AI safety.
2. Facilitate discussions among researchers and practitioners from diverse fields, including software engineering, AI, ethics, social sciences, and regulatory bodies, to address the responsible AI and AI safety engineering challenges.
3. Promote the development of new and improved software/AI engineering approaches to ensure AI systems are trustworthy and trusted throughout their lifecycle.


### Topics of Interest

Topics of interests include, but are not limited to:

- Requirement engineering for responsible AI and AI safety
- Responsible-AI-by-design and AI-safety-by-design software architecture
- Verification and validation for responsible AI and AI safety
- DevOps, MLOps, LLMOps, AgentOps for ensuring responsible AI and AI safety
- Development processes for responsible and safe AI systems
- Responsible AI and AI safety governance, assessment tools and techniques
- Reproducibility and traceability of AI systems
- Trust and trustworthiness of AI systems
- Human aspect of responsible AI and AI safety engineering
- Responsible AI and AI safety engineering for next-generation foundation model based AI systems (e.g., LLM-based agents) 
- Case studies from certain high priority domains (e.g., financial services, science discovery, health, environment, energy)


**Two types of contributions will be considered:**

- A research or experience full paper with 8 pages max. Papers describing the challenges, starting results, vision papers, or the experience papers from or in cooperation with the practitioners are encouraged.
- A short research or experience paper with 4 pages max. The same topics as for long papers.

### Submission Guidelines
1. All submissions must be in English and in PDF format. Papers must not exceed the page limits that are listed above. It is not possible to pay for extra pages.
2. The Single-Anonymous Review process is employed by RAIE'25.

Other detailed submission policies and guidelines for RAIE'25 are in line with the [ICSE Research Track Submission Process](https://conf.researchr.org/track/icse-2025/icse-2025-research-track#submission-process). Please note all papers must conform to the IEEE conference proceedings template, specified in the IEEE Conference Proceedings Formatting Guidelines (title in 24pt font and full text in 10pt type, LaTeX users must use \documentclass[10pt,conference]{IEEEtran} without including the compsoc or compsocconf options).


### Important Dates

**Submission Deadline:** 11 November 2024
<br>
**Notification of Acceptance:**  1 December 2024
<br>
**Camera Ready:** 5 February 2025

### Organizing Committee

#### Workshop Organisers
**Qinghua Lu** - *CSIRO's Data61*, Sydney, Australia ([qinghua.lu@data61.csiro.au](mailto:qinghua.lu@data61.csiro.au))  

**Foutse Khomh** - *Polytechnique Montreal*, Montreal, Quebec, Canada ([foutse.khomh@polymtl.ca](mailto:foutse.khomh@polymtl.ca))

**Apostol T. Vassilev** - *NIST*, Washington DC, US ([apostol.vassilev@nist.gov](mailto:apostol.vassilev@nist.gov))

**Maximilian Poretschkin** - *Fraunhofer*, Sankt Augustin, Germany ([maximilian.poretschkin@iais.fraunhofer.de](mailto:maximilian.poretschkin@iais.fraunhofer.de))


#### Program Committee
TBA
