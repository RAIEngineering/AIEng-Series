---
layout: page
title: RAIE 2025
---

<!-- <p><img src="/img/pierrebourque.jpg" width="200" /><a href="https://profs.etsmtl.ca/pbourque">Pierre Bourque</a> - ing., Ph.D.</p> -->

# 3rd International Workshop on Responsible AI Engineering (RAIE'24)

***Co-located with [47th International Conference on Software Engineering (ICSE 2025)](https://conf.researchr.org/home/icse-2024), Ottawa, Ontario, Canada, April 27-May 3, 2025***

### Theme & Goals

The rapid advancements in advanced AI, exemplified by the release of ChatGPT, Bard, and other large language model (LLM)-based chatbots, have garnered significant global attention and raised substantial concerns regarding responsible AI and AI safety. The opaque nature and swift progress of AI technologies necessitate that AI systems are developed and used responsibly throughout their entire lifecycle and are trusted by the humans who rely on them.

In recent years, numerous ethical regulations, principles, and guidelines for responsible AI have been issued by governments, research organizations, and enterprises. However, these principles are typically very high-level and do not provide concrete guidance for technologists on how to implement AI responsibly. For instance, the Australian AI Ethics Framework states that AI systems should respect "human-centred values," but this leaves many questions unanswered, such as which values are prioritized and how these values can be designed for, implemented, and tracked in an AI system. Developing responsible AI systems goes beyond fixing traditional software code "bugs" and providing theoretical guarantees for algorithms. New and improved software/AI engineering approaches are required to ensure that AI systems are trustworthy throughout their entire lifecycle and trusted by those who use and rely on them.

Achieving responsible AI engineering—building adequate software engineering tools to support the responsible development of AI systems—requires a comprehensive understanding of human expectations and the utilization context of AI systems. This workshop aims to bring together researchers and practitioners not only in software engineering and AI but also ethicists, and experts from social sciences and regulatory bodies to build a community that will tackle the responsible AI engineering challenges practitioners face in developing AI systems responsibly. Traditional software engineering methods are not sufficient to tackle the unique challenges posed by advanced AI technologies. This workshop will provide valuable insights into how software engineering can evolve to meet these challenges, focusing on aspects such as requirement engineering, architecture and design, verification and validation, and operational processes like DevOps and MLOps. By bringing together experts from various fields, the workshop aims to foster interdisciplinary collaboration that will drive the advancement of responsible AI engineering practices.

### Topics of Interest

Topics of interests include, but are not limited to:

- Requirement engineering for responsible AI
- Software architecture and design of responsible AI systems
- Verification and validation for responsible AI systems
- DevOps, MLOps, MLSecOps, LLMOps for responsible AI systems
- Development processes for responsible AI systems
- Responsible AI governance, assessment tools/techniques
- Reproducibility and traceability of AI systems
- Trust and trustworthiness of AI systems
- Human aspect of responsible AI engineering
- Responsible AI engineering for next-generation foundation model based AI systems (e.g., LLM-based) 
- Regulatory and policy implications
- Education and training in responsible AI

The workshop will be highly interactive, including invited keynotes/talks, paper presentations for different topics in the area of responsible AI engineering. 

**Two types of contributions will be considered:**

- A research or experience full paper with 8 pages max. Papers describing the challenges, starting results, vision papers, or the experience papers from or in cooperation with the practitioners are encouraged.
- A short research or experience paper with 4 pages max. The same topics as for long papers.

### Submission Guidelines
1. All submissions must be in English and in PDF format. Papers must not exceed the page limits that are listed above. It is not possible to pay for extra pages.
2. The Single-Anonymous Review process is employed by RAIE'25.

Detailed submission policies and guidelines for RAIE'24 are in line with the [ICSE Research track Submission Process](https://conf.researchr.org/track/icse-2024/icse-2024-research-track#submission-process). Please note all papers must follow the [ACM formatting 
instructions](https://www.acm.org/publications/proceedings-template). 


### Important Dates

**Submission Deadline:** 11 November 2024
<br>
**Notification of Acceptance:**  1 December 2024
<br>
**Camera Ready:** 5 February 2025

### Organizing Committee

#### Workshop Organisers

- [Qinghua Lu](https://people.csiro.au/L/Q/Qinghua-Lu), CSIRO, Australia, <qinghua.lu@data61.csiro.au>
<!-- - [Apostol Vassilev](https://www.nist.gov/people/apostol-vassilev), NIST, USA, <apostol.vassilev@nist.gov>
- [Foutse Khomh](https://www.polymtl.ca/expertises/en/khomh-foutse), Polytechnique Montréal, Canada, <foutse.khomh@polymtl.ca>
- [Maximilian Poretschkin](https://de.linkedin.com/in/maximilian-poretschkin-00137a161), Fraunhofer IAIS, Germany, <maximilian.poretschkin@iais.fraunhofer.de> -->


#### Program Committee

• TBA
